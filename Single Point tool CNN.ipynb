{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "instrumental-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tensorflow.keras.layers import Conv2D,Conv1D, MaxPooling2D,MaxPooling1D\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "nutritional-somalia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Median</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Sample Variance</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Range</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Count</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142599</td>\n",
       "      <td>365.0</td>\n",
       "      <td>366</td>\n",
       "      <td>1.425985</td>\n",
       "      <td>2.033434</td>\n",
       "      <td>-0.897223</td>\n",
       "      <td>-0.105681</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>368</td>\n",
       "      <td>36513</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126027</td>\n",
       "      <td>368.0</td>\n",
       "      <td>368</td>\n",
       "      <td>1.260271</td>\n",
       "      <td>1.588283</td>\n",
       "      <td>-0.395387</td>\n",
       "      <td>0.265678</td>\n",
       "      <td>5</td>\n",
       "      <td>366</td>\n",
       "      <td>371</td>\n",
       "      <td>36826</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097333</td>\n",
       "      <td>371.0</td>\n",
       "      <td>371</td>\n",
       "      <td>0.973331</td>\n",
       "      <td>0.947374</td>\n",
       "      <td>-0.400559</td>\n",
       "      <td>-0.177908</td>\n",
       "      <td>4</td>\n",
       "      <td>369</td>\n",
       "      <td>373</td>\n",
       "      <td>37089</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.099372</td>\n",
       "      <td>373.0</td>\n",
       "      <td>373</td>\n",
       "      <td>0.993718</td>\n",
       "      <td>0.987475</td>\n",
       "      <td>-0.824843</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>4</td>\n",
       "      <td>371</td>\n",
       "      <td>375</td>\n",
       "      <td>37332</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094554</td>\n",
       "      <td>376.0</td>\n",
       "      <td>376</td>\n",
       "      <td>0.945537</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>-0.187940</td>\n",
       "      <td>-0.205709</td>\n",
       "      <td>5</td>\n",
       "      <td>373</td>\n",
       "      <td>378</td>\n",
       "      <td>37557</td>\n",
       "      <td>100</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1.069559</td>\n",
       "      <td>325.0</td>\n",
       "      <td>330</td>\n",
       "      <td>10.695586</td>\n",
       "      <td>114.395556</td>\n",
       "      <td>0.435310</td>\n",
       "      <td>-0.668873</td>\n",
       "      <td>54</td>\n",
       "      <td>290</td>\n",
       "      <td>344</td>\n",
       "      <td>32322</td>\n",
       "      <td>100</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.131819</td>\n",
       "      <td>324.5</td>\n",
       "      <td>327</td>\n",
       "      <td>11.318190</td>\n",
       "      <td>128.101414</td>\n",
       "      <td>-0.008641</td>\n",
       "      <td>-0.555331</td>\n",
       "      <td>53</td>\n",
       "      <td>291</td>\n",
       "      <td>344</td>\n",
       "      <td>32314</td>\n",
       "      <td>100</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1.137146</td>\n",
       "      <td>316.5</td>\n",
       "      <td>316</td>\n",
       "      <td>11.371464</td>\n",
       "      <td>129.310202</td>\n",
       "      <td>-0.046520</td>\n",
       "      <td>-0.069875</td>\n",
       "      <td>56</td>\n",
       "      <td>285</td>\n",
       "      <td>341</td>\n",
       "      <td>31677</td>\n",
       "      <td>100</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1.971869</td>\n",
       "      <td>344.5</td>\n",
       "      <td>346</td>\n",
       "      <td>19.718688</td>\n",
       "      <td>388.826667</td>\n",
       "      <td>-0.073315</td>\n",
       "      <td>-1.185157</td>\n",
       "      <td>74</td>\n",
       "      <td>283</td>\n",
       "      <td>357</td>\n",
       "      <td>33304</td>\n",
       "      <td>100</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.961634</td>\n",
       "      <td>347.5</td>\n",
       "      <td>348</td>\n",
       "      <td>3.846535</td>\n",
       "      <td>14.795833</td>\n",
       "      <td>2.440078</td>\n",
       "      <td>1.747884</td>\n",
       "      <td>13</td>\n",
       "      <td>345</td>\n",
       "      <td>358</td>\n",
       "      <td>5577</td>\n",
       "      <td>16</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Standard Error  Median  Mode  Standard Deviation  Sample Variance  \\\n",
       "0          0.142599   365.0   366            1.425985         2.033434   \n",
       "1          0.126027   368.0   368            1.260271         1.588283   \n",
       "2          0.097333   371.0   371            0.973331         0.947374   \n",
       "3          0.099372   373.0   373            0.993718         0.987475   \n",
       "4          0.094554   376.0   376            0.945537         0.894040   \n",
       "..              ...     ...   ...                 ...              ...   \n",
       "295        1.069559   325.0   330           10.695586       114.395556   \n",
       "296        1.131819   324.5   327           11.318190       128.101414   \n",
       "297        1.137146   316.5   316           11.371464       129.310202   \n",
       "298        1.971869   344.5   346           19.718688       388.826667   \n",
       "299        0.961634   347.5   348            3.846535        14.795833   \n",
       "\n",
       "     Kurtosis  Skewness  Range  Minimum  Maximum    Sum  Count    Condition  \n",
       "0   -0.897223 -0.105681      6      362      368  36513    100         Good  \n",
       "1   -0.395387  0.265678      5      366      371  36826    100         Good  \n",
       "2   -0.400559 -0.177908      4      369      373  37089    100         Good  \n",
       "3   -0.824843  0.072199      4      371      375  37332    100         Good  \n",
       "4   -0.187940 -0.205709      5      373      378  37557    100         Good  \n",
       "..        ...       ...    ...      ...      ...    ...    ...          ...  \n",
       "295  0.435310 -0.668873     54      290      344  32322    100  Crater wear  \n",
       "296 -0.008641 -0.555331     53      291      344  32314    100  Crater wear  \n",
       "297 -0.046520 -0.069875     56      285      341  31677    100  Crater wear  \n",
       "298 -0.073315 -1.185157     74      283      357  33304    100  Crater wear  \n",
       "299  2.440078  1.747884     13      345      358   5577     16  Crater wear  \n",
       "\n",
       "[300 rows x 13 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing dataset\n",
    "df = pd.read_csv('SinglePointData.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "threatened-opening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Median</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Sample Variance</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Range</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Count</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.836431</td>\n",
       "      <td>0.859060</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.013297</td>\n",
       "      <td>0.527690</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.919298</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.933748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.858736</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.026231</td>\n",
       "      <td>0.567926</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.881041</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.026097</td>\n",
       "      <td>0.519864</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.951133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.895911</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.546963</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.950877</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.958468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.918216</td>\n",
       "      <td>0.926174</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.031577</td>\n",
       "      <td>0.516852</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.965259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.135093</td>\n",
       "      <td>0.539033</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.135093</td>\n",
       "      <td>0.019020</td>\n",
       "      <td>0.047641</td>\n",
       "      <td>0.466669</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.807250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.143150</td>\n",
       "      <td>0.535316</td>\n",
       "      <td>0.597315</td>\n",
       "      <td>0.143150</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.478971</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.670175</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.807009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.475836</td>\n",
       "      <td>0.523490</td>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.021502</td>\n",
       "      <td>0.035222</td>\n",
       "      <td>0.531569</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.787782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.251861</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.724832</td>\n",
       "      <td>0.251861</td>\n",
       "      <td>0.064676</td>\n",
       "      <td>0.034532</td>\n",
       "      <td>0.410731</td>\n",
       "      <td>0.260714</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.836890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.121126</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.046459</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.099311</td>\n",
       "      <td>0.728520</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Crater wear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Standard Error    Median      Mode  Standard Deviation  Sample Variance  \\\n",
       "0          0.015135  0.836431  0.859060            0.015135         0.000327   \n",
       "1          0.012991  0.858736  0.872483            0.012991         0.000253   \n",
       "2          0.009277  0.881041  0.892617            0.009277         0.000147   \n",
       "3          0.009541  0.895911  0.906040            0.009541         0.000153   \n",
       "4          0.008918  0.918216  0.926174            0.008918         0.000138   \n",
       "..              ...       ...       ...                 ...              ...   \n",
       "295        0.135093  0.539033  0.617450            0.135093         0.019020   \n",
       "296        0.143150  0.535316  0.597315            0.143150         0.021301   \n",
       "297        0.143839  0.475836  0.523490            0.143839         0.021502   \n",
       "298        0.251861  0.684015  0.724832            0.251861         0.064676   \n",
       "299        0.121126  0.706320  0.738255            0.046459         0.002451   \n",
       "\n",
       "     Kurtosis  Skewness     Range   Minimum  Maximum       Sum  Count  \\\n",
       "0    0.013297  0.527690  0.017857  0.919298     0.59  0.933748    1.0   \n",
       "1    0.026231  0.567926  0.014286  0.933333     0.62  0.943195    1.0   \n",
       "2    0.026097  0.519864  0.010714  0.943860     0.64  0.951133    1.0   \n",
       "3    0.015162  0.546963  0.010714  0.950877     0.66  0.958468    1.0   \n",
       "4    0.031577  0.516852  0.014286  0.957895     0.69  0.965259    1.0   \n",
       "..        ...       ...       ...       ...      ...       ...    ...   \n",
       "295  0.047641  0.466669  0.189286  0.666667     0.35  0.807250    1.0   \n",
       "296  0.036199  0.478971  0.185714  0.670175     0.35  0.807009    1.0   \n",
       "297  0.035222  0.531569  0.196429  0.649123     0.32  0.787782    1.0   \n",
       "298  0.034532  0.410731  0.260714  0.642105     0.48  0.836890    1.0   \n",
       "299  0.099311  0.728520  0.042857  0.859649     0.49  0.000000    0.0   \n",
       "\n",
       "       Condition  \n",
       "0           Good  \n",
       "1           Good  \n",
       "2           Good  \n",
       "3           Good  \n",
       "4           Good  \n",
       "..           ...  \n",
       "295  Crater wear  \n",
       "296  Crater wear  \n",
       "297  Crater wear  \n",
       "298  Crater wear  \n",
       "299  Crater wear  \n",
       "\n",
       "[300 rows x 13 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the columms \n",
    "\n",
    "cols_to_scale = ['Standard Error','Median','Mode', 'Standard Deviation', 'Sample Variance','Kurtosis', 'Skewness', 'Range', 'Minimum', 'Maximum', 'Sum', 'Count']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-infrared",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-incidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "broadband-representation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Good\n",
       "1             Good\n",
       "2             Good\n",
       "3             Good\n",
       "4             Good\n",
       "          ...     \n",
       "295    Crater wear\n",
       "296    Crater wear\n",
       "297    Crater wear\n",
       "298    Crater wear\n",
       "299    Crater wear\n",
       "Name: Condition, Length: 300, dtype: object"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "sized-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/38957/keras-conv1d-for-simple-data-target-prediction\n",
    "X = df[['Standard Error','Median','Mode', 'Standard Deviation', 'Sample Variance','Kurtosis', 'Skewness', 'Range', 'Minimum', 'Maximum', 'Sum', 'Count']]\n",
    "Y = df['Condition']\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.asarray(X), np.asarray(Y), test_size=0.33, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "adult-robin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 12)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "acting-guidance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 12)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "educated-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.reshape(201,6,1)\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "lovely-patrol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "logical-medline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition_Crater wear</th>\n",
       "      <th>Condition_Flank Wear</th>\n",
       "      <th>Condition_Good</th>\n",
       "      <th>Condition_Nose Wear</th>\n",
       "      <th>Condition_Notch wear</th>\n",
       "      <th>Condition_Tool breakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Condition_Crater wear  Condition_Flank Wear  Condition_Good  \\\n",
       "0                        0                     0               0   \n",
       "1                        0                     1               0   \n",
       "2                        0                     0               0   \n",
       "3                        0                     0               0   \n",
       "4                        1                     0               0   \n",
       "..                     ...                   ...             ...   \n",
       "196                      1                     0               0   \n",
       "197                      0                     0               1   \n",
       "198                      0                     0               0   \n",
       "199                      1                     0               0   \n",
       "200                      0                     0               0   \n",
       "\n",
       "     Condition_Nose Wear  Condition_Notch wear  Condition_Tool breakage   \n",
       "0                      0                     1                         0  \n",
       "1                      0                     0                         0  \n",
       "2                      1                     0                         0  \n",
       "3                      0                     1                         0  \n",
       "4                      0                     0                         0  \n",
       "..                   ...                   ...                       ...  \n",
       "196                    0                     0                         0  \n",
       "197                    0                     0                         0  \n",
       "198                    0                     1                         0  \n",
       "199                    0                     0                         0  \n",
       "200                    0                     1                         0  \n",
       "\n",
       "[201 rows x 6 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "y_train_binary = pd.get_dummies(y_train, prefix='Condition')\n",
    "y_train_binary\n",
    "y_test_binary = pd.get_dummies(y_test, prefix='Condition')\n",
    "y_train_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bulgarian-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 6)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_binary = y_train_binary.values\n",
    "y_train_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "regulated-circumstances",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 6)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binary = y_test_binary.values\n",
    "y_test_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "unique-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "dimensional-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 6)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_shape = (12,1)\n",
    "y_train_binary.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "empirical-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 1\n",
    "#y_train_binary.reshape(201,6,1)\n",
    "#y_test_binary.reshape(99,6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "imposed-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 12)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "upset-ensemble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 12)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "confused-maryland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00776274],\n",
       "        [0.69516729],\n",
       "        [0.72483221],\n",
       "        ...,\n",
       "        [0.4       ],\n",
       "        [0.87688268],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.22646227],\n",
       "        [0.49070632],\n",
       "        [0.73154362],\n",
       "        ...,\n",
       "        [0.44      ],\n",
       "        [0.79581057],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.14209133],\n",
       "        [0.31598513],\n",
       "        [0.29530201],\n",
       "        ...,\n",
       "        [0.14      ],\n",
       "        [0.72415562],\n",
       "        [1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00722454],\n",
       "        [0.70260223],\n",
       "        [0.73154362],\n",
       "        ...,\n",
       "        [0.4       ],\n",
       "        [0.8797199 ],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.45498035],\n",
       "        [0.0929368 ],\n",
       "        [0.17449664],\n",
       "        ...,\n",
       "        [0.13      ],\n",
       "        [0.62388699],\n",
       "        [1.        ]],\n",
       "\n",
       "       [[0.00772604],\n",
       "        [0.69516729],\n",
       "        [0.72483221],\n",
       "        ...,\n",
       "        [0.4       ],\n",
       "        [0.87700341],\n",
       "        [1.        ]]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add 1\n",
    "x_train = x_train.reshape(201, 12, 1)\n",
    "x_test = x_test.reshape(99, 12,1)\n",
    "x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "functional-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original model\n",
    "#model = Sequential()\n",
    "#model.add(Conv1D(32, (3), input_shape=(12,1), activation='relu'))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "about-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model tuning\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, (2), input_shape=(12,1), activation='relu'))\n",
    "model.add(Conv1D(16, (2), input_shape=(12,1), activation='relu'))\n",
    "#model.add(MaxPooling1D(2))\n",
    "#model.add(Conv1D(1000, (3), input_shape=(12,1), activation='relu'))\n",
    "#model.add(Conv1D(500, (2), input_shape=(12,1), activation='relu'))\n",
    "#model.add(Conv1D(300, (2), input_shape=(12,1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "connected-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "explicit-pierre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 11, 32)            96        \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 10, 16)            1040      \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 64)                10304     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 6)                 42        \n",
      "=================================================================\n",
      "Total params: 12,198\n",
      "Trainable params: 12,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "alike-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 201 samples\n",
      "Epoch 1/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7936 - acc: 0.1741\n",
      "Epoch 2/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7935 - acc: 0.1741\n",
      "Epoch 3/1000\n",
      "201/201 [==============================] - 0s 798us/sample - loss: 1.7934 - acc: 0.1741\n",
      "Epoch 4/1000\n",
      "201/201 [==============================] - 0s 845us/sample - loss: 1.7934 - acc: 0.1741\n",
      "Epoch 5/1000\n",
      "201/201 [==============================] - 0s 838us/sample - loss: 1.7933 - acc: 0.1741\n",
      "Epoch 6/1000\n",
      "201/201 [==============================] - 0s 842us/sample - loss: 1.7932 - acc: 0.1741\n",
      "Epoch 7/1000\n",
      "201/201 [==============================] - 0s 829us/sample - loss: 1.7932 - acc: 0.1741\n",
      "Epoch 8/1000\n",
      "201/201 [==============================] - 0s 863us/sample - loss: 1.7931 - acc: 0.1741\n",
      "Epoch 9/1000\n",
      "201/201 [==============================] - 0s 862us/sample - loss: 1.7930 - acc: 0.1741\n",
      "Epoch 10/1000\n",
      "201/201 [==============================] - 0s 809us/sample - loss: 1.7929 - acc: 0.1741\n",
      "Epoch 11/1000\n",
      "201/201 [==============================] - 0s 812us/sample - loss: 1.7929 - acc: 0.1741\n",
      "Epoch 12/1000\n",
      "201/201 [==============================] - 0s 862us/sample - loss: 1.7928 - acc: 0.1741\n",
      "Epoch 13/1000\n",
      "201/201 [==============================] - 0s 848us/sample - loss: 1.7927 - acc: 0.1741\n",
      "Epoch 14/1000\n",
      "201/201 [==============================] - 0s 967us/sample - loss: 1.7926 - acc: 0.1741\n",
      "Epoch 15/1000\n",
      "201/201 [==============================] - 0s 978us/sample - loss: 1.7926 - acc: 0.1741\n",
      "Epoch 16/1000\n",
      "201/201 [==============================] - 0s 859us/sample - loss: 1.7925 - acc: 0.1741\n",
      "Epoch 17/1000\n",
      "201/201 [==============================] - 0s 869us/sample - loss: 1.7924 - acc: 0.1741\n",
      "Epoch 18/1000\n",
      "201/201 [==============================] - 0s 841us/sample - loss: 1.7924 - acc: 0.1741\n",
      "Epoch 19/1000\n",
      "201/201 [==============================] - 0s 914us/sample - loss: 1.7923 - acc: 0.1741\n",
      "Epoch 20/1000\n",
      "201/201 [==============================] - 0s 863us/sample - loss: 1.7922 - acc: 0.1741\n",
      "Epoch 21/1000\n",
      "201/201 [==============================] - 0s 830us/sample - loss: 1.7921 - acc: 0.1741\n",
      "Epoch 22/1000\n",
      "201/201 [==============================] - 0s 834us/sample - loss: 1.7921 - acc: 0.1741\n",
      "Epoch 23/1000\n",
      "201/201 [==============================] - 0s 879us/sample - loss: 1.7920 - acc: 0.1741\n",
      "Epoch 24/1000\n",
      "201/201 [==============================] - 0s 817us/sample - loss: 1.7919 - acc: 0.1741\n",
      "Epoch 25/1000\n",
      "201/201 [==============================] - 0s 840us/sample - loss: 1.7919 - acc: 0.1741\n",
      "Epoch 26/1000\n",
      "201/201 [==============================] - 0s 887us/sample - loss: 1.7918 - acc: 0.1741\n",
      "Epoch 27/1000\n",
      "201/201 [==============================] - 0s 854us/sample - loss: 1.7917 - acc: 0.1741\n",
      "Epoch 28/1000\n",
      "201/201 [==============================] - 0s 816us/sample - loss: 1.7917 - acc: 0.1741\n",
      "Epoch 29/1000\n",
      "201/201 [==============================] - 0s 939us/sample - loss: 1.7916 - acc: 0.1741\n",
      "Epoch 30/1000\n",
      "201/201 [==============================] - 0s 979us/sample - loss: 1.7915 - acc: 0.1741\n",
      "Epoch 31/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7915 - acc: 0.1741\n",
      "Epoch 32/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7914 - acc: 0.1741\n",
      "Epoch 33/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7914 - acc: 0.1741\n",
      "Epoch 34/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7913 - acc: 0.1741\n",
      "Epoch 35/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7913 - acc: 0.1741\n",
      "Epoch 36/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7912 - acc: 0.1741\n",
      "Epoch 37/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7912 - acc: 0.1741\n",
      "Epoch 38/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7911 - acc: 0.1741\n",
      "Epoch 39/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7910 - acc: 0.1741\n",
      "Epoch 40/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7910 - acc: 0.1741\n",
      "Epoch 41/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7909 - acc: 0.1741\n",
      "Epoch 42/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7909 - acc: 0.1741\n",
      "Epoch 43/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7908 - acc: 0.1741\n",
      "Epoch 44/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7908 - acc: 0.1741\n",
      "Epoch 45/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7907 - acc: 0.1741\n",
      "Epoch 46/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7907 - acc: 0.1741\n",
      "Epoch 47/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7906 - acc: 0.1741\n",
      "Epoch 48/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7906 - acc: 0.1741\n",
      "Epoch 49/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7905 - acc: 0.1741\n",
      "Epoch 50/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7905 - acc: 0.1741\n",
      "Epoch 51/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7904 - acc: 0.1741\n",
      "Epoch 52/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7904 - acc: 0.1741\n",
      "Epoch 53/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7903 - acc: 0.1741\n",
      "Epoch 54/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7903 - acc: 0.1741\n",
      "Epoch 55/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7902 - acc: 0.1741\n",
      "Epoch 56/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7902 - acc: 0.1741\n",
      "Epoch 57/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7901 - acc: 0.1741\n",
      "Epoch 58/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7901 - acc: 0.1741\n",
      "Epoch 59/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7900 - acc: 0.1741\n",
      "Epoch 60/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7900 - acc: 0.1741\n",
      "Epoch 61/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7899 - acc: 0.1741\n",
      "Epoch 62/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7899 - acc: 0.1741\n",
      "Epoch 63/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7899 - acc: 0.1741\n",
      "Epoch 64/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7898 - acc: 0.1741\n",
      "Epoch 65/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7898 - acc: 0.1741\n",
      "Epoch 66/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7897 - acc: 0.1741\n",
      "Epoch 67/1000\n",
      "201/201 [==============================] - 0s 935us/sample - loss: 1.7897 - acc: 0.1741\n",
      "Epoch 68/1000\n",
      "201/201 [==============================] - 0s 844us/sample - loss: 1.7896 - acc: 0.1741\n",
      "Epoch 69/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7896 - acc: 0.1741\n",
      "Epoch 70/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7895 - acc: 0.1741\n",
      "Epoch 71/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7895 - acc: 0.1741\n",
      "Epoch 72/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7895 - acc: 0.1741\n",
      "Epoch 73/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7894 - acc: 0.1741\n",
      "Epoch 74/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7894 - acc: 0.1741\n",
      "Epoch 75/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7894 - acc: 0.1741\n",
      "Epoch 76/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7893 - acc: 0.1741\n",
      "Epoch 77/1000\n",
      "201/201 [==============================] - 0s 915us/sample - loss: 1.7893 - acc: 0.1741\n",
      "Epoch 78/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7893 - acc: 0.1741\n",
      "Epoch 79/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7892 - acc: 0.1741\n",
      "Epoch 80/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7892 - acc: 0.1741\n",
      "Epoch 81/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7892 - acc: 0.1741\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7892 - acc: 0.1741\n",
      "Epoch 83/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7891 - acc: 0.1741\n",
      "Epoch 84/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7891 - acc: 0.1741\n",
      "Epoch 85/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7891 - acc: 0.1741\n",
      "Epoch 86/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7891 - acc: 0.1741\n",
      "Epoch 87/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7890 - acc: 0.1741\n",
      "Epoch 88/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7890 - acc: 0.1741\n",
      "Epoch 89/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7890 - acc: 0.1741\n",
      "Epoch 90/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7890 - acc: 0.1741\n",
      "Epoch 91/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7890 - acc: 0.1741\n",
      "Epoch 92/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7889 - acc: 0.1741\n",
      "Epoch 93/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7889 - acc: 0.1741\n",
      "Epoch 94/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7889 - acc: 0.1741\n",
      "Epoch 95/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7889 - acc: 0.1741\n",
      "Epoch 96/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7888 - acc: 0.175 - 0s 1ms/sample - loss: 1.7889 - acc: 0.1741\n",
      "Epoch 97/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7888 - acc: 0.1741\n",
      "Epoch 98/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7888 - acc: 0.1741\n",
      "Epoch 99/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7888 - acc: 0.1741\n",
      "Epoch 100/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7888 - acc: 0.1741\n",
      "Epoch 101/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7887 - acc: 0.1741\n",
      "Epoch 102/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7887 - acc: 0.1741\n",
      "Epoch 103/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7887 - acc: 0.1741\n",
      "Epoch 104/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7887 - acc: 0.1741\n",
      "Epoch 105/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7887 - acc: 0.1741\n",
      "Epoch 106/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7886 - acc: 0.1741\n",
      "Epoch 107/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7886 - acc: 0.1741\n",
      "Epoch 108/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7886 - acc: 0.1741\n",
      "Epoch 109/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7886 - acc: 0.1741\n",
      "Epoch 110/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7885 - acc: 0.1741\n",
      "Epoch 111/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7885 - acc: 0.1741\n",
      "Epoch 112/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7885 - acc: 0.1741\n",
      "Epoch 113/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7885 - acc: 0.1741\n",
      "Epoch 114/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7885 - acc: 0.1741\n",
      "Epoch 115/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7884 - acc: 0.1741\n",
      "Epoch 116/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7884 - acc: 0.1741\n",
      "Epoch 117/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7884 - acc: 0.1741\n",
      "Epoch 118/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7884 - acc: 0.1741\n",
      "Epoch 119/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7883 - acc: 0.1741\n",
      "Epoch 120/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7883 - acc: 0.1741\n",
      "Epoch 121/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7883 - acc: 0.1741\n",
      "Epoch 122/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7883 - acc: 0.1741\n",
      "Epoch 123/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7883 - acc: 0.1741\n",
      "Epoch 124/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7882 - acc: 0.1741\n",
      "Epoch 125/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7882 - acc: 0.1741\n",
      "Epoch 126/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7882 - acc: 0.1741\n",
      "Epoch 127/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7882 - acc: 0.1741\n",
      "Epoch 128/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7882 - acc: 0.1741\n",
      "Epoch 129/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7881 - acc: 0.1741\n",
      "Epoch 130/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7881 - acc: 0.1741\n",
      "Epoch 131/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7881 - acc: 0.1741\n",
      "Epoch 132/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7881 - acc: 0.1741\n",
      "Epoch 133/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7880 - acc: 0.1741\n",
      "Epoch 134/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7880 - acc: 0.1741\n",
      "Epoch 135/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7880 - acc: 0.1741\n",
      "Epoch 136/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7880 - acc: 0.1741\n",
      "Epoch 137/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7880 - acc: 0.1741\n",
      "Epoch 138/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7879 - acc: 0.1741\n",
      "Epoch 139/1000\n",
      "201/201 [==============================] - 0s 943us/sample - loss: 1.7879 - acc: 0.1741\n",
      "Epoch 140/1000\n",
      "201/201 [==============================] - 0s 869us/sample - loss: 1.7879 - acc: 0.1741\n",
      "Epoch 141/1000\n",
      "201/201 [==============================] - 0s 704us/sample - loss: 1.7879 - acc: 0.1741\n",
      "Epoch 142/1000\n",
      "201/201 [==============================] - 0s 743us/sample - loss: 1.7879 - acc: 0.1741\n",
      "Epoch 143/1000\n",
      "201/201 [==============================] - 0s 782us/sample - loss: 1.7878 - acc: 0.1741\n",
      "Epoch 144/1000\n",
      "201/201 [==============================] - 0s 712us/sample - loss: 1.7878 - acc: 0.1741\n",
      "Epoch 145/1000\n",
      "201/201 [==============================] - 0s 780us/sample - loss: 1.7878 - acc: 0.1741\n",
      "Epoch 146/1000\n",
      "201/201 [==============================] - 0s 877us/sample - loss: 1.7878 - acc: 0.1741\n",
      "Epoch 147/1000\n",
      "201/201 [==============================] - 0s 950us/sample - loss: 1.7877 - acc: 0.1741\n",
      "Epoch 148/1000\n",
      "201/201 [==============================] - 0s 998us/sample - loss: 1.7877 - acc: 0.1741\n",
      "Epoch 149/1000\n",
      "201/201 [==============================] - 0s 958us/sample - loss: 1.7877 - acc: 0.1741\n",
      "Epoch 150/1000\n",
      "201/201 [==============================] - 0s 942us/sample - loss: 1.7877 - acc: 0.1741\n",
      "Epoch 151/1000\n",
      "201/201 [==============================] - 0s 953us/sample - loss: 1.7877 - acc: 0.1741\n",
      "Epoch 152/1000\n",
      "201/201 [==============================] - 0s 967us/sample - loss: 1.7876 - acc: 0.1741\n",
      "Epoch 153/1000\n",
      "201/201 [==============================] - 0s 957us/sample - loss: 1.7876 - acc: 0.1741\n",
      "Epoch 154/1000\n",
      "201/201 [==============================] - 0s 996us/sample - loss: 1.7876 - acc: 0.1741\n",
      "Epoch 155/1000\n",
      "201/201 [==============================] - 0s 951us/sample - loss: 1.7876 - acc: 0.1741\n",
      "Epoch 156/1000\n",
      "201/201 [==============================] - 0s 953us/sample - loss: 1.7876 - acc: 0.1741\n",
      "Epoch 157/1000\n",
      "201/201 [==============================] - 0s 966us/sample - loss: 1.7875 - acc: 0.1741\n",
      "Epoch 158/1000\n",
      "201/201 [==============================] - 0s 937us/sample - loss: 1.7875 - acc: 0.1741\n",
      "Epoch 159/1000\n",
      "201/201 [==============================] - 0s 975us/sample - loss: 1.7875 - acc: 0.1741\n",
      "Epoch 160/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7875 - acc: 0.1741\n",
      "Epoch 161/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7874 - acc: 0.1741\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7874 - acc: 0.1741\n",
      "Epoch 163/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7874 - acc: 0.1741\n",
      "Epoch 164/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7874 - acc: 0.1741\n",
      "Epoch 165/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7874 - acc: 0.1741\n",
      "Epoch 166/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7873 - acc: 0.1741\n",
      "Epoch 167/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7873 - acc: 0.1741\n",
      "Epoch 168/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7873 - acc: 0.1741\n",
      "Epoch 169/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7873 - acc: 0.1741\n",
      "Epoch 170/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7873 - acc: 0.1741\n",
      "Epoch 171/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7872 - acc: 0.1741\n",
      "Epoch 172/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7872 - acc: 0.1741\n",
      "Epoch 173/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7872 - acc: 0.1741\n",
      "Epoch 174/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7872 - acc: 0.1741\n",
      "Epoch 175/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7871 - acc: 0.1741\n",
      "Epoch 176/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7871 - acc: 0.1741\n",
      "Epoch 177/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7871 - acc: 0.1741\n",
      "Epoch 178/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7871 - acc: 0.1741\n",
      "Epoch 179/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7871 - acc: 0.1741\n",
      "Epoch 180/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7870 - acc: 0.1741\n",
      "Epoch 181/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7870 - acc: 0.1741\n",
      "Epoch 182/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7870 - acc: 0.1741\n",
      "Epoch 183/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7870 - acc: 0.1741\n",
      "Epoch 184/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7869 - acc: 0.1741\n",
      "Epoch 185/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7869 - acc: 0.1741\n",
      "Epoch 186/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7869 - acc: 0.1741\n",
      "Epoch 187/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7869 - acc: 0.1741\n",
      "Epoch 188/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7869 - acc: 0.1741\n",
      "Epoch 189/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7868 - acc: 0.1741\n",
      "Epoch 190/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7868 - acc: 0.1741\n",
      "Epoch 191/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7868 - acc: 0.1741\n",
      "Epoch 192/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7868 - acc: 0.1741\n",
      "Epoch 193/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7867 - acc: 0.1741\n",
      "Epoch 194/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7867 - acc: 0.1741\n",
      "Epoch 195/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7867 - acc: 0.1741\n",
      "Epoch 196/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7867 - acc: 0.1741\n",
      "Epoch 197/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7866 - acc: 0.1741\n",
      "Epoch 198/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7866 - acc: 0.1741\n",
      "Epoch 199/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7866 - acc: 0.1741\n",
      "Epoch 200/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7866 - acc: 0.1741\n",
      "Epoch 201/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7866 - acc: 0.1741\n",
      "Epoch 202/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7865 - acc: 0.1741\n",
      "Epoch 203/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7865 - acc: 0.1741\n",
      "Epoch 204/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7865 - acc: 0.1741\n",
      "Epoch 205/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7865 - acc: 0.1741\n",
      "Epoch 206/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7864 - acc: 0.1741\n",
      "Epoch 207/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7864 - acc: 0.1741\n",
      "Epoch 208/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7864 - acc: 0.1741\n",
      "Epoch 209/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7864 - acc: 0.1741\n",
      "Epoch 210/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7864 - acc: 0.1741\n",
      "Epoch 211/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7863 - acc: 0.1741\n",
      "Epoch 212/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7863 - acc: 0.1741\n",
      "Epoch 213/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7863 - acc: 0.1741\n",
      "Epoch 214/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7863 - acc: 0.1741\n",
      "Epoch 215/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7862 - acc: 0.1741\n",
      "Epoch 216/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7862 - acc: 0.1741\n",
      "Epoch 217/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7862 - acc: 0.1741\n",
      "Epoch 218/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7862 - acc: 0.1741\n",
      "Epoch 219/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7862 - acc: 0.1741\n",
      "Epoch 220/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7861 - acc: 0.1741\n",
      "Epoch 221/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7861 - acc: 0.1741\n",
      "Epoch 222/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7861 - acc: 0.1741\n",
      "Epoch 223/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7861 - acc: 0.1741\n",
      "Epoch 224/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7861 - acc: 0.1741\n",
      "Epoch 225/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7860 - acc: 0.1741\n",
      "Epoch 226/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7860 - acc: 0.1741\n",
      "Epoch 227/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7860 - acc: 0.1741\n",
      "Epoch 228/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7860 - acc: 0.1741\n",
      "Epoch 229/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7859 - acc: 0.1741\n",
      "Epoch 230/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7859 - acc: 0.1741\n",
      "Epoch 231/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7859 - acc: 0.1741\n",
      "Epoch 232/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7859 - acc: 0.1741\n",
      "Epoch 233/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7859 - acc: 0.1741\n",
      "Epoch 234/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7858 - acc: 0.1741\n",
      "Epoch 235/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7858 - acc: 0.1741\n",
      "Epoch 236/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7858 - acc: 0.1741\n",
      "Epoch 237/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7858 - acc: 0.1741\n",
      "Epoch 238/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7858 - acc: 0.1741\n",
      "Epoch 239/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7857 - acc: 0.1741\n",
      "Epoch 240/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7857 - acc: 0.1741\n",
      "Epoch 241/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7857 - acc: 0.1741\n",
      "Epoch 242/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7857 - acc: 0.1741\n",
      "Epoch 243/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7856 - acc: 0.1741\n",
      "Epoch 244/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7856 - acc: 0.1741\n",
      "Epoch 245/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7856 - acc: 0.1741\n",
      "Epoch 246/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7856 - acc: 0.1741\n",
      "Epoch 247/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7856 - acc: 0.1741\n",
      "Epoch 248/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7855 - acc: 0.1741\n",
      "Epoch 249/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7855 - acc: 0.1741\n",
      "Epoch 250/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7855 - acc: 0.1741\n",
      "Epoch 251/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7855 - acc: 0.1741\n",
      "Epoch 252/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7855 - acc: 0.1741\n",
      "Epoch 253/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7858 - acc: 0.1842  - 0s 1ms/sample - loss: 1.7854 - acc: 0.1741\n",
      "Epoch 254/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7854 - acc: 0.1741\n",
      "Epoch 255/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7854 - acc: 0.1741\n",
      "Epoch 256/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7854 - acc: 0.1741\n",
      "Epoch 257/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7854 - acc: 0.1741\n",
      "Epoch 258/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7853 - acc: 0.1741\n",
      "Epoch 259/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7853 - acc: 0.1741\n",
      "Epoch 260/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7853 - acc: 0.1741\n",
      "Epoch 261/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7853 - acc: 0.1741\n",
      "Epoch 262/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7852 - acc: 0.1741\n",
      "Epoch 263/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7852 - acc: 0.1741\n",
      "Epoch 264/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7852 - acc: 0.1741\n",
      "Epoch 265/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7852 - acc: 0.1741\n",
      "Epoch 266/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7852 - acc: 0.1741\n",
      "Epoch 267/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7851 - acc: 0.1741\n",
      "Epoch 268/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7851 - acc: 0.1741\n",
      "Epoch 269/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7851 - acc: 0.1741\n",
      "Epoch 270/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7851 - acc: 0.1741\n",
      "Epoch 271/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7851 - acc: 0.1741\n",
      "Epoch 272/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7850 - acc: 0.1741\n",
      "Epoch 273/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7850 - acc: 0.1741\n",
      "Epoch 274/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7850 - acc: 0.1741\n",
      "Epoch 275/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7850 - acc: 0.1741\n",
      "Epoch 276/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7849 - acc: 0.1741\n",
      "Epoch 277/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7849 - acc: 0.1741\n",
      "Epoch 278/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7849 - acc: 0.1741\n",
      "Epoch 279/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7849 - acc: 0.1741\n",
      "Epoch 280/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7849 - acc: 0.1741\n",
      "Epoch 281/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7848 - acc: 0.1741\n",
      "Epoch 282/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7848 - acc: 0.1741\n",
      "Epoch 283/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7848 - acc: 0.1741\n",
      "Epoch 284/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7848 - acc: 0.1741\n",
      "Epoch 285/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7847 - acc: 0.1741\n",
      "Epoch 286/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7847 - acc: 0.1741\n",
      "Epoch 287/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7847 - acc: 0.1741\n",
      "Epoch 288/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7847 - acc: 0.1741\n",
      "Epoch 289/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7847 - acc: 0.1741\n",
      "Epoch 290/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7846 - acc: 0.1741\n",
      "Epoch 291/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7846 - acc: 0.1741\n",
      "Epoch 292/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7846 - acc: 0.1741\n",
      "Epoch 293/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7843 - acc: 0.1823 - 0s 1ms/sample - loss: 1.7846 - acc: 0.1741\n",
      "Epoch 294/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7846 - acc: 0.1741\n",
      "Epoch 295/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7845 - acc: 0.1741\n",
      "Epoch 296/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7845 - acc: 0.1741\n",
      "Epoch 297/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7845 - acc: 0.1741\n",
      "Epoch 298/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7845 - acc: 0.1741\n",
      "Epoch 299/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7844 - acc: 0.1741\n",
      "Epoch 300/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7844 - acc: 0.1741\n",
      "Epoch 301/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7844 - acc: 0.1741\n",
      "Epoch 302/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7844 - acc: 0.1741\n",
      "Epoch 303/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7844 - acc: 0.1741\n",
      "Epoch 304/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7843 - acc: 0.1741\n",
      "Epoch 305/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7843 - acc: 0.1741\n",
      "Epoch 306/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7843 - acc: 0.1741\n",
      "Epoch 307/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7843 - acc: 0.1741\n",
      "Epoch 308/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7842 - acc: 0.1741\n",
      "Epoch 309/1000\n",
      "201/201 [==============================] - 0s 792us/sample - loss: 1.7842 - acc: 0.1741\n",
      "Epoch 310/1000\n",
      "201/201 [==============================] - 0s 828us/sample - loss: 1.7842 - acc: 0.1741\n",
      "Epoch 311/1000\n",
      "201/201 [==============================] - 0s 792us/sample - loss: 1.7842 - acc: 0.1741\n",
      "Epoch 312/1000\n",
      "201/201 [==============================] - 0s 854us/sample - loss: 1.7842 - acc: 0.1741\n",
      "Epoch 313/1000\n",
      "201/201 [==============================] - 0s 777us/sample - loss: 1.7841 - acc: 0.1741\n",
      "Epoch 314/1000\n",
      "201/201 [==============================] - 0s 811us/sample - loss: 1.7841 - acc: 0.1741\n",
      "Epoch 315/1000\n",
      "201/201 [==============================] - 0s 816us/sample - loss: 1.7841 - acc: 0.1741\n",
      "Epoch 316/1000\n",
      "201/201 [==============================] - 0s 832us/sample - loss: 1.7841 - acc: 0.1741\n",
      "Epoch 317/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7841 - acc: 0.1741\n",
      "Epoch 318/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7840 - acc: 0.1741\n",
      "Epoch 319/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7840 - acc: 0.1741\n",
      "Epoch 320/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7840 - acc: 0.1741\n",
      "Epoch 321/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7840 - acc: 0.1741\n",
      "Epoch 322/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7839 - acc: 0.1741\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7839 - acc: 0.1741\n",
      "Epoch 324/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7839 - acc: 0.1741\n",
      "Epoch 325/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7839 - acc: 0.1741\n",
      "Epoch 326/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7839 - acc: 0.1741\n",
      "Epoch 327/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7838 - acc: 0.1741\n",
      "Epoch 328/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7838 - acc: 0.1741\n",
      "Epoch 329/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7838 - acc: 0.1741\n",
      "Epoch 330/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7838 - acc: 0.1741\n",
      "Epoch 331/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7837 - acc: 0.1741\n",
      "Epoch 332/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7837 - acc: 0.1741\n",
      "Epoch 333/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7837 - acc: 0.1741\n",
      "Epoch 334/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7837 - acc: 0.1741\n",
      "Epoch 335/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7837 - acc: 0.1741\n",
      "Epoch 336/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7836 - acc: 0.1741\n",
      "Epoch 337/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7836 - acc: 0.1741\n",
      "Epoch 338/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7836 - acc: 0.1741\n",
      "Epoch 339/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7836 - acc: 0.1741\n",
      "Epoch 340/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7836 - acc: 0.1741\n",
      "Epoch 341/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7835 - acc: 0.1741\n",
      "Epoch 342/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7835 - acc: 0.1741\n",
      "Epoch 343/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7835 - acc: 0.1741\n",
      "Epoch 344/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7835 - acc: 0.1741\n",
      "Epoch 345/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7834 - acc: 0.1741\n",
      "Epoch 346/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7834 - acc: 0.1741\n",
      "Epoch 347/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7834 - acc: 0.1741\n",
      "Epoch 348/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7834 - acc: 0.1741\n",
      "Epoch 349/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7834 - acc: 0.1741\n",
      "Epoch 350/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7833 - acc: 0.1741\n",
      "Epoch 351/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7833 - acc: 0.1741\n",
      "Epoch 352/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7833 - acc: 0.1741\n",
      "Epoch 353/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7833 - acc: 0.1741\n",
      "Epoch 354/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7832 - acc: 0.1741\n",
      "Epoch 355/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7832 - acc: 0.1741\n",
      "Epoch 356/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7832 - acc: 0.1741\n",
      "Epoch 357/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7832 - acc: 0.1741\n",
      "Epoch 358/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7832 - acc: 0.1741\n",
      "Epoch 359/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7831 - acc: 0.1741\n",
      "Epoch 360/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7831 - acc: 0.1741\n",
      "Epoch 361/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7831 - acc: 0.1741\n",
      "Epoch 362/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7831 - acc: 0.1741\n",
      "Epoch 363/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7830 - acc: 0.1741\n",
      "Epoch 364/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7830 - acc: 0.1741\n",
      "Epoch 365/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7830 - acc: 0.1741\n",
      "Epoch 366/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7830 - acc: 0.1741\n",
      "Epoch 367/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7830 - acc: 0.1741\n",
      "Epoch 368/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7829 - acc: 0.1741\n",
      "Epoch 369/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7829 - acc: 0.1741\n",
      "Epoch 370/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7829 - acc: 0.1741\n",
      "Epoch 371/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7829 - acc: 0.1741\n",
      "Epoch 372/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7828 - acc: 0.1741\n",
      "Epoch 373/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7828 - acc: 0.1741\n",
      "Epoch 374/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7828 - acc: 0.1741\n",
      "Epoch 375/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7828 - acc: 0.1741\n",
      "Epoch 376/1000\n",
      "201/201 [==============================] - 0s 738us/sample - loss: 1.7828 - acc: 0.1741\n",
      "Epoch 377/1000\n",
      "201/201 [==============================] - 0s 966us/sample - loss: 1.7827 - acc: 0.1741\n",
      "Epoch 378/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7827 - acc: 0.1741\n",
      "Epoch 379/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7827 - acc: 0.1741\n",
      "Epoch 380/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7827 - acc: 0.1741\n",
      "Epoch 381/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7826 - acc: 0.1741\n",
      "Epoch 382/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7826 - acc: 0.1741\n",
      "Epoch 383/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7826 - acc: 0.1741\n",
      "Epoch 384/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7826 - acc: 0.1741\n",
      "Epoch 385/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7825 - acc: 0.1741\n",
      "Epoch 386/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7825 - acc: 0.1741\n",
      "Epoch 387/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7825 - acc: 0.1741\n",
      "Epoch 388/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7825 - acc: 0.1741\n",
      "Epoch 389/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7825 - acc: 0.1741\n",
      "Epoch 390/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7824 - acc: 0.1741\n",
      "Epoch 391/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7824 - acc: 0.1741\n",
      "Epoch 392/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7824 - acc: 0.1741\n",
      "Epoch 393/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7824 - acc: 0.1741\n",
      "Epoch 394/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7823 - acc: 0.1741\n",
      "Epoch 395/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7823 - acc: 0.1741\n",
      "Epoch 396/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7823 - acc: 0.1741\n",
      "Epoch 397/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7823 - acc: 0.1741\n",
      "Epoch 398/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7823 - acc: 0.1741\n",
      "Epoch 399/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7822 - acc: 0.1741\n",
      "Epoch 400/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7822 - acc: 0.1741\n",
      "Epoch 401/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7822 - acc: 0.1741\n",
      "Epoch 402/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7822 - acc: 0.1741\n",
      "Epoch 403/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7821 - acc: 0.1741\n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7821 - acc: 0.1741\n",
      "Epoch 405/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7821 - acc: 0.1741\n",
      "Epoch 406/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7821 - acc: 0.1741\n",
      "Epoch 407/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7820 - acc: 0.1741\n",
      "Epoch 408/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7823 - acc: 0.180 - 0s 1ms/sample - loss: 1.7820 - acc: 0.1741\n",
      "Epoch 409/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7820 - acc: 0.1741\n",
      "Epoch 410/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7820 - acc: 0.1741\n",
      "Epoch 411/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7820 - acc: 0.1741\n",
      "Epoch 412/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7819 - acc: 0.1741\n",
      "Epoch 413/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7819 - acc: 0.1741\n",
      "Epoch 414/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7819 - acc: 0.1741\n",
      "Epoch 415/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7819 - acc: 0.1741\n",
      "Epoch 416/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7818 - acc: 0.1741\n",
      "Epoch 417/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7818 - acc: 0.1741\n",
      "Epoch 418/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7818 - acc: 0.1741\n",
      "Epoch 419/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7818 - acc: 0.1741\n",
      "Epoch 420/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7817 - acc: 0.1741\n",
      "Epoch 421/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7817 - acc: 0.1741\n",
      "Epoch 422/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7817 - acc: 0.1741\n",
      "Epoch 423/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7817 - acc: 0.1741\n",
      "Epoch 424/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7817 - acc: 0.1741\n",
      "Epoch 425/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7816 - acc: 0.1741\n",
      "Epoch 426/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7816 - acc: 0.1741\n",
      "Epoch 427/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7816 - acc: 0.1741\n",
      "Epoch 428/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7816 - acc: 0.1741\n",
      "Epoch 429/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7815 - acc: 0.1741\n",
      "Epoch 430/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7815 - acc: 0.1741\n",
      "Epoch 431/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7815 - acc: 0.1741\n",
      "Epoch 432/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7815 - acc: 0.1741\n",
      "Epoch 433/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7814 - acc: 0.1741\n",
      "Epoch 434/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7814 - acc: 0.1741\n",
      "Epoch 435/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7814 - acc: 0.1741\n",
      "Epoch 436/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7814 - acc: 0.1741\n",
      "Epoch 437/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7813 - acc: 0.1741\n",
      "Epoch 438/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7813 - acc: 0.1741\n",
      "Epoch 439/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7813 - acc: 0.1741\n",
      "Epoch 440/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7813 - acc: 0.1741\n",
      "Epoch 441/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7812 - acc: 0.1741\n",
      "Epoch 442/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7812 - acc: 0.1741\n",
      "Epoch 443/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7812 - acc: 0.1741\n",
      "Epoch 444/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7812 - acc: 0.1741\n",
      "Epoch 445/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7811 - acc: 0.1741\n",
      "Epoch 446/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7811 - acc: 0.1741\n",
      "Epoch 447/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7811 - acc: 0.1741\n",
      "Epoch 448/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7811 - acc: 0.1741\n",
      "Epoch 449/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7810 - acc: 0.1741\n",
      "Epoch 450/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7810 - acc: 0.1741\n",
      "Epoch 451/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7810 - acc: 0.1741\n",
      "Epoch 452/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7810 - acc: 0.1741\n",
      "Epoch 453/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7809 - acc: 0.1741\n",
      "Epoch 454/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7809 - acc: 0.1741\n",
      "Epoch 455/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7809 - acc: 0.1741\n",
      "Epoch 456/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7809 - acc: 0.1741\n",
      "Epoch 457/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7808 - acc: 0.1741\n",
      "Epoch 458/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7808 - acc: 0.1741\n",
      "Epoch 459/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7808 - acc: 0.1741\n",
      "Epoch 460/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7808 - acc: 0.1741\n",
      "Epoch 461/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7803 - acc: 0.182 - 0s 1ms/sample - loss: 1.7808 - acc: 0.1741\n",
      "Epoch 462/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7807 - acc: 0.1741\n",
      "Epoch 463/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7807 - acc: 0.1741\n",
      "Epoch 464/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7807 - acc: 0.1741\n",
      "Epoch 465/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7807 - acc: 0.1741\n",
      "Epoch 466/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7806 - acc: 0.1741\n",
      "Epoch 467/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7806 - acc: 0.1741\n",
      "Epoch 468/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7806 - acc: 0.1741\n",
      "Epoch 469/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7806 - acc: 0.1741\n",
      "Epoch 470/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7805 - acc: 0.1741\n",
      "Epoch 471/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7805 - acc: 0.1741\n",
      "Epoch 472/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7805 - acc: 0.1741\n",
      "Epoch 473/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7805 - acc: 0.1741\n",
      "Epoch 474/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7804 - acc: 0.1741\n",
      "Epoch 475/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7804 - acc: 0.1741\n",
      "Epoch 476/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7804 - acc: 0.1741\n",
      "Epoch 477/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7803 - acc: 0.1741\n",
      "Epoch 478/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7803 - acc: 0.1741\n",
      "Epoch 479/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7803 - acc: 0.1741\n",
      "Epoch 480/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7803 - acc: 0.1741\n",
      "Epoch 481/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7802 - acc: 0.1741\n",
      "Epoch 482/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7802 - acc: 0.1741\n",
      "Epoch 483/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7802 - acc: 0.1741\n",
      "Epoch 484/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7802 - acc: 0.1741\n",
      "Epoch 485/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7801 - acc: 0.1741\n",
      "Epoch 486/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7801 - acc: 0.1741\n",
      "Epoch 487/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7801 - acc: 0.1741\n",
      "Epoch 488/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7801 - acc: 0.1741\n",
      "Epoch 489/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7800 - acc: 0.1741\n",
      "Epoch 490/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7800 - acc: 0.1741\n",
      "Epoch 491/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7800 - acc: 0.1741\n",
      "Epoch 492/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7800 - acc: 0.1741\n",
      "Epoch 493/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7799 - acc: 0.1741\n",
      "Epoch 494/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7799 - acc: 0.1741\n",
      "Epoch 495/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7799 - acc: 0.1741\n",
      "Epoch 496/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7799 - acc: 0.1741\n",
      "Epoch 497/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7798 - acc: 0.1741\n",
      "Epoch 498/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7798 - acc: 0.1741\n",
      "Epoch 499/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7798 - acc: 0.1741\n",
      "Epoch 500/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7798 - acc: 0.1741\n",
      "Epoch 501/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7797 - acc: 0.1741\n",
      "Epoch 502/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7797 - acc: 0.1741\n",
      "Epoch 503/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7797 - acc: 0.1741\n",
      "Epoch 504/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7796 - acc: 0.1741\n",
      "Epoch 505/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7796 - acc: 0.1741\n",
      "Epoch 506/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7796 - acc: 0.1741\n",
      "Epoch 507/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7796 - acc: 0.1741\n",
      "Epoch 508/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7795 - acc: 0.1741\n",
      "Epoch 509/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7795 - acc: 0.1741\n",
      "Epoch 510/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7795 - acc: 0.1741\n",
      "Epoch 511/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7795 - acc: 0.1741\n",
      "Epoch 512/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7794 - acc: 0.1741\n",
      "Epoch 513/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7794 - acc: 0.1741\n",
      "Epoch 514/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7794 - acc: 0.1741\n",
      "Epoch 515/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7794 - acc: 0.1741\n",
      "Epoch 516/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7796 - acc: 0.168 - 0s 1ms/sample - loss: 1.7793 - acc: 0.1741\n",
      "Epoch 517/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7793 - acc: 0.1741\n",
      "Epoch 518/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7793 - acc: 0.1741\n",
      "Epoch 519/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7793 - acc: 0.1741\n",
      "Epoch 520/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7792 - acc: 0.1741\n",
      "Epoch 521/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7792 - acc: 0.1741\n",
      "Epoch 522/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7792 - acc: 0.1741\n",
      "Epoch 523/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7791 - acc: 0.1741\n",
      "Epoch 524/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7791 - acc: 0.1741\n",
      "Epoch 525/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7791 - acc: 0.1741\n",
      "Epoch 526/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7791 - acc: 0.1741\n",
      "Epoch 527/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7790 - acc: 0.1741\n",
      "Epoch 528/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7790 - acc: 0.1741\n",
      "Epoch 529/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7790 - acc: 0.1741\n",
      "Epoch 530/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7790 - acc: 0.1741\n",
      "Epoch 531/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7789 - acc: 0.1741\n",
      "Epoch 532/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7789 - acc: 0.1741\n",
      "Epoch 533/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7789 - acc: 0.1741\n",
      "Epoch 534/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7789 - acc: 0.1741\n",
      "Epoch 535/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7791 - acc: 0.166 - 0s 1ms/sample - loss: 1.7788 - acc: 0.1741\n",
      "Epoch 536/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7788 - acc: 0.1741\n",
      "Epoch 537/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7788 - acc: 0.1741\n",
      "Epoch 538/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7787 - acc: 0.1741\n",
      "Epoch 539/1000\n",
      "201/201 [==============================] - 0s 952us/sample - loss: 1.7787 - acc: 0.1741\n",
      "Epoch 540/1000\n",
      "201/201 [==============================] - 0s 830us/sample - loss: 1.7787 - acc: 0.1741\n",
      "Epoch 541/1000\n",
      "201/201 [==============================] - 0s 751us/sample - loss: 1.7787 - acc: 0.1741\n",
      "Epoch 542/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7786 - acc: 0.1741\n",
      "Epoch 543/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7786 - acc: 0.1741\n",
      "Epoch 544/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7786 - acc: 0.1741\n",
      "Epoch 545/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7786 - acc: 0.1741\n",
      "Epoch 546/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7785 - acc: 0.1741\n",
      "Epoch 547/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7785 - acc: 0.1741\n",
      "Epoch 548/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7785 - acc: 0.1741\n",
      "Epoch 549/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7785 - acc: 0.1741\n",
      "Epoch 550/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7784 - acc: 0.1741\n",
      "Epoch 551/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7784 - acc: 0.1741\n",
      "Epoch 552/1000\n",
      "201/201 [==============================] - 0s 742us/sample - loss: 1.7784 - acc: 0.1741\n",
      "Epoch 553/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7783 - acc: 0.1741\n",
      "Epoch 554/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7783 - acc: 0.1741\n",
      "Epoch 555/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7783 - acc: 0.1741\n",
      "Epoch 556/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7783 - acc: 0.1741\n",
      "Epoch 557/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7782 - acc: 0.1741\n",
      "Epoch 558/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7782 - acc: 0.1741\n",
      "Epoch 559/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7782 - acc: 0.1741\n",
      "Epoch 560/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7781 - acc: 0.1741\n",
      "Epoch 561/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7781 - acc: 0.1741\n",
      "Epoch 562/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7781 - acc: 0.1741\n",
      "Epoch 563/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7781 - acc: 0.1741\n",
      "Epoch 564/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7780 - acc: 0.1741\n",
      "Epoch 565/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7780 - acc: 0.1741\n",
      "Epoch 566/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7780 - acc: 0.1741\n",
      "Epoch 567/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7780 - acc: 0.1741\n",
      "Epoch 568/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7779 - acc: 0.1741\n",
      "Epoch 569/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7779 - acc: 0.1741\n",
      "Epoch 570/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7779 - acc: 0.1741\n",
      "Epoch 571/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7778 - acc: 0.1741\n",
      "Epoch 572/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7778 - acc: 0.1741\n",
      "Epoch 573/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7778 - acc: 0.1741\n",
      "Epoch 574/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7778 - acc: 0.1741\n",
      "Epoch 575/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7777 - acc: 0.1741\n",
      "Epoch 576/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7777 - acc: 0.1741\n",
      "Epoch 577/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7777 - acc: 0.1741\n",
      "Epoch 578/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7777 - acc: 0.1741\n",
      "Epoch 579/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7776 - acc: 0.1741\n",
      "Epoch 580/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7776 - acc: 0.1741\n",
      "Epoch 581/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7776 - acc: 0.1741\n",
      "Epoch 582/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7775 - acc: 0.1741\n",
      "Epoch 583/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7775 - acc: 0.1741\n",
      "Epoch 584/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7775 - acc: 0.1741\n",
      "Epoch 585/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7775 - acc: 0.1741\n",
      "Epoch 586/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7774 - acc: 0.1741\n",
      "Epoch 587/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7774 - acc: 0.1741\n",
      "Epoch 588/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7774 - acc: 0.1741\n",
      "Epoch 589/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7773 - acc: 0.1741\n",
      "Epoch 590/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7773 - acc: 0.1741\n",
      "Epoch 591/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7773 - acc: 0.1741\n",
      "Epoch 592/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7773 - acc: 0.1741\n",
      "Epoch 593/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7772 - acc: 0.1741\n",
      "Epoch 594/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7772 - acc: 0.1741\n",
      "Epoch 595/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7772 - acc: 0.1741\n",
      "Epoch 596/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7771 - acc: 0.1741\n",
      "Epoch 597/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7771 - acc: 0.1741\n",
      "Epoch 598/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7771 - acc: 0.1741\n",
      "Epoch 599/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7770 - acc: 0.1741\n",
      "Epoch 600/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7770 - acc: 0.1741\n",
      "Epoch 601/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7770 - acc: 0.1741\n",
      "Epoch 602/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7770 - acc: 0.1741\n",
      "Epoch 603/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7769 - acc: 0.1741\n",
      "Epoch 604/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7769 - acc: 0.1741\n",
      "Epoch 605/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7769 - acc: 0.1741\n",
      "Epoch 606/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7768 - acc: 0.1741\n",
      "Epoch 607/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7768 - acc: 0.1741\n",
      "Epoch 608/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7768 - acc: 0.1741\n",
      "Epoch 609/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7768 - acc: 0.1741\n",
      "Epoch 610/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7767 - acc: 0.1741\n",
      "Epoch 611/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7767 - acc: 0.1741\n",
      "Epoch 612/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7767 - acc: 0.1741\n",
      "Epoch 613/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7766 - acc: 0.1741\n",
      "Epoch 614/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7766 - acc: 0.1741\n",
      "Epoch 615/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7766 - acc: 0.1741\n",
      "Epoch 616/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7766 - acc: 0.1741\n",
      "Epoch 617/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7765 - acc: 0.1741\n",
      "Epoch 618/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7765 - acc: 0.1741\n",
      "Epoch 619/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7765 - acc: 0.1741\n",
      "Epoch 620/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7764 - acc: 0.1741\n",
      "Epoch 621/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7764 - acc: 0.1741\n",
      "Epoch 622/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7764 - acc: 0.1741\n",
      "Epoch 623/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7763 - acc: 0.1741\n",
      "Epoch 624/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7763 - acc: 0.1741\n",
      "Epoch 625/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7763 - acc: 0.1741\n",
      "Epoch 626/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7763 - acc: 0.1741\n",
      "Epoch 627/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7762 - acc: 0.1741\n",
      "Epoch 628/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7762 - acc: 0.1741\n",
      "Epoch 629/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7762 - acc: 0.1741\n",
      "Epoch 630/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7761 - acc: 0.1741\n",
      "Epoch 631/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7761 - acc: 0.1741\n",
      "Epoch 632/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7761 - acc: 0.1741\n",
      "Epoch 633/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7760 - acc: 0.1741\n",
      "Epoch 634/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7760 - acc: 0.1741\n",
      "Epoch 635/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7760 - acc: 0.1741\n",
      "Epoch 636/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7760 - acc: 0.1741\n",
      "Epoch 637/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7759 - acc: 0.1741\n",
      "Epoch 638/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7759 - acc: 0.1741\n",
      "Epoch 639/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7759 - acc: 0.1741\n",
      "Epoch 640/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7758 - acc: 0.1741\n",
      "Epoch 641/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7758 - acc: 0.1741\n",
      "Epoch 642/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7758 - acc: 0.1741\n",
      "Epoch 643/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7757 - acc: 0.1741\n",
      "Epoch 644/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7757 - acc: 0.1741\n",
      "Epoch 645/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7757 - acc: 0.1741\n",
      "Epoch 646/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7756 - acc: 0.1741\n",
      "Epoch 647/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7756 - acc: 0.1741\n",
      "Epoch 648/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7756 - acc: 0.1741\n",
      "Epoch 649/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7756 - acc: 0.1741\n",
      "Epoch 650/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7755 - acc: 0.1741\n",
      "Epoch 651/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7755 - acc: 0.1741\n",
      "Epoch 652/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7755 - acc: 0.1741\n",
      "Epoch 653/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7754 - acc: 0.1741\n",
      "Epoch 654/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7754 - acc: 0.1741\n",
      "Epoch 655/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7754 - acc: 0.1741\n",
      "Epoch 656/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7753 - acc: 0.1741\n",
      "Epoch 657/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7753 - acc: 0.1741\n",
      "Epoch 658/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7753 - acc: 0.1741\n",
      "Epoch 659/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7752 - acc: 0.1741\n",
      "Epoch 660/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7752 - acc: 0.1741\n",
      "Epoch 661/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7752 - acc: 0.1741\n",
      "Epoch 662/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7752 - acc: 0.1741\n",
      "Epoch 663/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7751 - acc: 0.1741\n",
      "Epoch 664/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7751 - acc: 0.1741\n",
      "Epoch 665/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7751 - acc: 0.1741\n",
      "Epoch 666/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7750 - acc: 0.1741\n",
      "Epoch 667/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7750 - acc: 0.1741\n",
      "Epoch 668/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7750 - acc: 0.1741\n",
      "Epoch 669/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7749 - acc: 0.1741\n",
      "Epoch 670/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7749 - acc: 0.1741\n",
      "Epoch 671/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7749 - acc: 0.1741\n",
      "Epoch 672/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7749 - acc: 0.1741\n",
      "Epoch 673/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7748 - acc: 0.1741\n",
      "Epoch 674/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7748 - acc: 0.1741\n",
      "Epoch 675/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7748 - acc: 0.1741\n",
      "Epoch 676/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7747 - acc: 0.1741\n",
      "Epoch 677/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7747 - acc: 0.1741\n",
      "Epoch 678/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7747 - acc: 0.1741\n",
      "Epoch 679/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7746 - acc: 0.1741\n",
      "Epoch 680/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7746 - acc: 0.1741\n",
      "Epoch 681/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7746 - acc: 0.1741\n",
      "Epoch 682/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7746 - acc: 0.1741\n",
      "Epoch 683/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7745 - acc: 0.1741\n",
      "Epoch 684/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7745 - acc: 0.1741\n",
      "Epoch 685/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7745 - acc: 0.1741\n",
      "Epoch 686/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7744 - acc: 0.1741\n",
      "Epoch 687/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7744 - acc: 0.1741\n",
      "Epoch 688/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7744 - acc: 0.1741\n",
      "Epoch 689/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7743 - acc: 0.1741\n",
      "Epoch 690/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7743 - acc: 0.1741\n",
      "Epoch 691/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7743 - acc: 0.1741\n",
      "Epoch 692/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7743 - acc: 0.1741\n",
      "Epoch 693/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7742 - acc: 0.1741\n",
      "Epoch 694/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7742 - acc: 0.1741\n",
      "Epoch 695/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7742 - acc: 0.1741\n",
      "Epoch 696/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7741 - acc: 0.1741\n",
      "Epoch 697/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7741 - acc: 0.1741\n",
      "Epoch 698/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7741 - acc: 0.1741\n",
      "Epoch 699/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7740 - acc: 0.1741\n",
      "Epoch 700/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7740 - acc: 0.1741\n",
      "Epoch 701/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7740 - acc: 0.1741\n",
      "Epoch 702/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7740 - acc: 0.1741\n",
      "Epoch 703/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7739 - acc: 0.1741\n",
      "Epoch 704/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7739 - acc: 0.1741\n",
      "Epoch 705/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7739 - acc: 0.1741\n",
      "Epoch 706/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7738 - acc: 0.1741\n",
      "Epoch 707/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7738 - acc: 0.1741\n",
      "Epoch 708/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7738 - acc: 0.1741\n",
      "Epoch 709/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7737 - acc: 0.1741\n",
      "Epoch 710/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7737 - acc: 0.1741\n",
      "Epoch 711/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7737 - acc: 0.1741\n",
      "Epoch 712/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7736 - acc: 0.1741\n",
      "Epoch 713/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7736 - acc: 0.1741\n",
      "Epoch 714/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7736 - acc: 0.1741\n",
      "Epoch 715/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7735 - acc: 0.1741\n",
      "Epoch 716/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7735 - acc: 0.1741\n",
      "Epoch 717/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7735 - acc: 0.1741\n",
      "Epoch 718/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7735 - acc: 0.1741\n",
      "Epoch 719/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7734 - acc: 0.1741\n",
      "Epoch 720/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7734 - acc: 0.1741\n",
      "Epoch 721/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7734 - acc: 0.1741\n",
      "Epoch 722/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7733 - acc: 0.1741\n",
      "Epoch 723/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7733 - acc: 0.1741\n",
      "Epoch 724/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7733 - acc: 0.1741\n",
      "Epoch 725/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7732 - acc: 0.1741\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7732 - acc: 0.1741\n",
      "Epoch 727/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7732 - acc: 0.1741\n",
      "Epoch 728/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7731 - acc: 0.1741\n",
      "Epoch 729/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7731 - acc: 0.1741\n",
      "Epoch 730/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7731 - acc: 0.1741\n",
      "Epoch 731/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7730 - acc: 0.1741\n",
      "Epoch 732/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7730 - acc: 0.1741\n",
      "Epoch 733/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7730 - acc: 0.1741\n",
      "Epoch 734/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7729 - acc: 0.1741\n",
      "Epoch 735/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7729 - acc: 0.1741\n",
      "Epoch 736/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7729 - acc: 0.1741\n",
      "Epoch 737/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7729 - acc: 0.1741\n",
      "Epoch 738/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7728 - acc: 0.1741\n",
      "Epoch 739/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7728 - acc: 0.1741\n",
      "Epoch 740/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7728 - acc: 0.1741\n",
      "Epoch 741/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7727 - acc: 0.1741\n",
      "Epoch 742/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7727 - acc: 0.1741\n",
      "Epoch 743/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7727 - acc: 0.1741\n",
      "Epoch 744/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7726 - acc: 0.1741\n",
      "Epoch 745/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7726 - acc: 0.1741\n",
      "Epoch 746/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7726 - acc: 0.1741\n",
      "Epoch 747/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7725 - acc: 0.1741\n",
      "Epoch 748/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7725 - acc: 0.1741\n",
      "Epoch 749/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7725 - acc: 0.1741\n",
      "Epoch 750/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7724 - acc: 0.1741\n",
      "Epoch 751/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7724 - acc: 0.1741\n",
      "Epoch 752/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7724 - acc: 0.1741\n",
      "Epoch 753/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7723 - acc: 0.1741\n",
      "Epoch 754/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7723 - acc: 0.1741\n",
      "Epoch 755/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7723 - acc: 0.1741\n",
      "Epoch 756/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7722 - acc: 0.1741\n",
      "Epoch 757/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7722 - acc: 0.1741\n",
      "Epoch 758/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7722 - acc: 0.1741\n",
      "Epoch 759/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7721 - acc: 0.1741\n",
      "Epoch 760/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7721 - acc: 0.1741\n",
      "Epoch 761/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7721 - acc: 0.1741\n",
      "Epoch 762/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7720 - acc: 0.1741\n",
      "Epoch 763/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7720 - acc: 0.1741\n",
      "Epoch 764/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7720 - acc: 0.1741\n",
      "Epoch 765/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7719 - acc: 0.1741\n",
      "Epoch 766/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7719 - acc: 0.1741\n",
      "Epoch 767/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7719 - acc: 0.1741\n",
      "Epoch 768/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7718 - acc: 0.1741\n",
      "Epoch 769/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7718 - acc: 0.1741\n",
      "Epoch 770/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7718 - acc: 0.1741\n",
      "Epoch 771/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7717 - acc: 0.1741\n",
      "Epoch 772/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7717 - acc: 0.1741\n",
      "Epoch 773/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7717 - acc: 0.1741\n",
      "Epoch 774/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7716 - acc: 0.1741\n",
      "Epoch 775/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7716 - acc: 0.1741\n",
      "Epoch 776/1000\n",
      "201/201 [==============================] - ETA: 0s - loss: 1.7711 - acc: 0.184 - 0s 1ms/sample - loss: 1.7716 - acc: 0.1741\n",
      "Epoch 777/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7715 - acc: 0.1741\n",
      "Epoch 778/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7715 - acc: 0.1741\n",
      "Epoch 779/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7715 - acc: 0.1741\n",
      "Epoch 780/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7714 - acc: 0.1741\n",
      "Epoch 781/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7714 - acc: 0.1741\n",
      "Epoch 782/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7714 - acc: 0.1741\n",
      "Epoch 783/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7713 - acc: 0.1741\n",
      "Epoch 784/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7713 - acc: 0.1741\n",
      "Epoch 785/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7713 - acc: 0.1741\n",
      "Epoch 786/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7712 - acc: 0.1741\n",
      "Epoch 787/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7712 - acc: 0.1741\n",
      "Epoch 788/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7712 - acc: 0.1741\n",
      "Epoch 789/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7711 - acc: 0.1741\n",
      "Epoch 790/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7711 - acc: 0.1741\n",
      "Epoch 791/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7711 - acc: 0.1741\n",
      "Epoch 792/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7710 - acc: 0.1741\n",
      "Epoch 793/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7710 - acc: 0.1741\n",
      "Epoch 794/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7710 - acc: 0.1741\n",
      "Epoch 795/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7709 - acc: 0.1741\n",
      "Epoch 796/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7709 - acc: 0.1741\n",
      "Epoch 797/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7709 - acc: 0.1741\n",
      "Epoch 798/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7708 - acc: 0.1741\n",
      "Epoch 799/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7708 - acc: 0.1741\n",
      "Epoch 800/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7708 - acc: 0.1741\n",
      "Epoch 801/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7707 - acc: 0.1741\n",
      "Epoch 802/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7707 - acc: 0.1741\n",
      "Epoch 803/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7707 - acc: 0.1741\n",
      "Epoch 804/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7706 - acc: 0.1741\n",
      "Epoch 805/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7706 - acc: 0.1741\n",
      "Epoch 806/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7706 - acc: 0.1741\n",
      "Epoch 807/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7705 - acc: 0.1741\n",
      "Epoch 808/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7705 - acc: 0.1741\n",
      "Epoch 809/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7705 - acc: 0.1741\n",
      "Epoch 810/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7704 - acc: 0.1741\n",
      "Epoch 811/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7704 - acc: 0.1741\n",
      "Epoch 812/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7704 - acc: 0.1741\n",
      "Epoch 813/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7703 - acc: 0.1741\n",
      "Epoch 814/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7703 - acc: 0.1741\n",
      "Epoch 815/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7703 - acc: 0.1741\n",
      "Epoch 816/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7702 - acc: 0.1741\n",
      "Epoch 817/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7702 - acc: 0.1741\n",
      "Epoch 818/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7702 - acc: 0.1741\n",
      "Epoch 819/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7701 - acc: 0.1741\n",
      "Epoch 820/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7701 - acc: 0.1741\n",
      "Epoch 821/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7701 - acc: 0.1741\n",
      "Epoch 822/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7700 - acc: 0.1741\n",
      "Epoch 823/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7700 - acc: 0.1741\n",
      "Epoch 824/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7700 - acc: 0.1741\n",
      "Epoch 825/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7699 - acc: 0.1741\n",
      "Epoch 826/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7699 - acc: 0.1741\n",
      "Epoch 827/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7699 - acc: 0.1741\n",
      "Epoch 828/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7698 - acc: 0.1741\n",
      "Epoch 829/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7698 - acc: 0.1741\n",
      "Epoch 830/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7697 - acc: 0.1741\n",
      "Epoch 831/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7697 - acc: 0.1741\n",
      "Epoch 832/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7697 - acc: 0.1741\n",
      "Epoch 833/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7696 - acc: 0.1741\n",
      "Epoch 834/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7696 - acc: 0.1741\n",
      "Epoch 835/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7696 - acc: 0.1741\n",
      "Epoch 836/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7695 - acc: 0.1741\n",
      "Epoch 837/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7695 - acc: 0.1741\n",
      "Epoch 838/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7695 - acc: 0.1741\n",
      "Epoch 839/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7694 - acc: 0.1741\n",
      "Epoch 840/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7694 - acc: 0.1741\n",
      "Epoch 841/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7694 - acc: 0.1741\n",
      "Epoch 842/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7693 - acc: 0.1741\n",
      "Epoch 843/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7693 - acc: 0.1741\n",
      "Epoch 844/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7692 - acc: 0.1741\n",
      "Epoch 845/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7692 - acc: 0.1741\n",
      "Epoch 846/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7692 - acc: 0.1741\n",
      "Epoch 847/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7691 - acc: 0.1741\n",
      "Epoch 848/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7691 - acc: 0.1741\n",
      "Epoch 849/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7691 - acc: 0.1741\n",
      "Epoch 850/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7690 - acc: 0.1741\n",
      "Epoch 851/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7690 - acc: 0.1741\n",
      "Epoch 852/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7690 - acc: 0.1741\n",
      "Epoch 853/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7689 - acc: 0.1741\n",
      "Epoch 854/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7689 - acc: 0.1741\n",
      "Epoch 855/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7689 - acc: 0.1741\n",
      "Epoch 856/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7688 - acc: 0.1741\n",
      "Epoch 857/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7688 - acc: 0.1741\n",
      "Epoch 858/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7687 - acc: 0.1741\n",
      "Epoch 859/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7687 - acc: 0.1741\n",
      "Epoch 860/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7687 - acc: 0.1741\n",
      "Epoch 861/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7686 - acc: 0.1741\n",
      "Epoch 862/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7686 - acc: 0.1741\n",
      "Epoch 863/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7686 - acc: 0.1741\n",
      "Epoch 864/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7685 - acc: 0.1741\n",
      "Epoch 865/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7685 - acc: 0.1741\n",
      "Epoch 866/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7685 - acc: 0.1741\n",
      "Epoch 867/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7684 - acc: 0.1741\n",
      "Epoch 868/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7684 - acc: 0.1741\n",
      "Epoch 869/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7684 - acc: 0.1741\n",
      "Epoch 870/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7683 - acc: 0.1741\n",
      "Epoch 871/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7683 - acc: 0.1741\n",
      "Epoch 872/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7683 - acc: 0.1741\n",
      "Epoch 873/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7682 - acc: 0.1741\n",
      "Epoch 874/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7682 - acc: 0.1741\n",
      "Epoch 875/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7681 - acc: 0.1741\n",
      "Epoch 876/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7681 - acc: 0.1741\n",
      "Epoch 877/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7681 - acc: 0.1741\n",
      "Epoch 878/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7680 - acc: 0.1741\n",
      "Epoch 879/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7680 - acc: 0.1741\n",
      "Epoch 880/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7680 - acc: 0.1741\n",
      "Epoch 881/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7679 - acc: 0.1741\n",
      "Epoch 882/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7679 - acc: 0.1741\n",
      "Epoch 883/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7679 - acc: 0.1741\n",
      "Epoch 884/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7678 - acc: 0.1741\n",
      "Epoch 885/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7678 - acc: 0.1741\n",
      "Epoch 886/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7678 - acc: 0.1741\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7677 - acc: 0.1741\n",
      "Epoch 888/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7677 - acc: 0.1741\n",
      "Epoch 889/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7676 - acc: 0.1741\n",
      "Epoch 890/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7676 - acc: 0.1741\n",
      "Epoch 891/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7676 - acc: 0.1741\n",
      "Epoch 892/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7675 - acc: 0.1741\n",
      "Epoch 893/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7675 - acc: 0.1741\n",
      "Epoch 894/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7675 - acc: 0.1741\n",
      "Epoch 895/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7674 - acc: 0.1741\n",
      "Epoch 896/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7674 - acc: 0.1741\n",
      "Epoch 897/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7673 - acc: 0.1741\n",
      "Epoch 898/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7673 - acc: 0.1741\n",
      "Epoch 899/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7673 - acc: 0.1741\n",
      "Epoch 900/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7672 - acc: 0.1741\n",
      "Epoch 901/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7672 - acc: 0.1741\n",
      "Epoch 902/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7672 - acc: 0.1741\n",
      "Epoch 903/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7671 - acc: 0.1741\n",
      "Epoch 904/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7671 - acc: 0.1741\n",
      "Epoch 905/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7670 - acc: 0.1741\n",
      "Epoch 906/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7670 - acc: 0.1741\n",
      "Epoch 907/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7670 - acc: 0.1741\n",
      "Epoch 908/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7669 - acc: 0.1741\n",
      "Epoch 909/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7669 - acc: 0.1741\n",
      "Epoch 910/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7669 - acc: 0.1741\n",
      "Epoch 911/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7668 - acc: 0.1741\n",
      "Epoch 912/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7668 - acc: 0.1741\n",
      "Epoch 913/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7667 - acc: 0.1741\n",
      "Epoch 914/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7667 - acc: 0.1741\n",
      "Epoch 915/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7667 - acc: 0.1741\n",
      "Epoch 916/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7666 - acc: 0.1741\n",
      "Epoch 917/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7666 - acc: 0.1741\n",
      "Epoch 918/1000\n",
      "201/201 [==============================] - 0s 760us/sample - loss: 1.7665 - acc: 0.1741\n",
      "Epoch 919/1000\n",
      "201/201 [==============================] - 0s 761us/sample - loss: 1.7665 - acc: 0.1741\n",
      "Epoch 920/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7665 - acc: 0.1741\n",
      "Epoch 921/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7664 - acc: 0.1741\n",
      "Epoch 922/1000\n",
      "201/201 [==============================] - 0s 847us/sample - loss: 1.7664 - acc: 0.1741\n",
      "Epoch 923/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7663 - acc: 0.1741\n",
      "Epoch 924/1000\n",
      "201/201 [==============================] - 0s 824us/sample - loss: 1.7663 - acc: 0.1741\n",
      "Epoch 925/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7663 - acc: 0.1741\n",
      "Epoch 926/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7662 - acc: 0.1741\n",
      "Epoch 927/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7662 - acc: 0.1741\n",
      "Epoch 928/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7662 - acc: 0.1741\n",
      "Epoch 929/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7661 - acc: 0.1741\n",
      "Epoch 930/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7661 - acc: 0.1741\n",
      "Epoch 931/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7660 - acc: 0.1741\n",
      "Epoch 932/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7660 - acc: 0.1741\n",
      "Epoch 933/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7659 - acc: 0.1741\n",
      "Epoch 934/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7659 - acc: 0.1741 0s - loss: 1.7667 - acc: 0.\n",
      "Epoch 935/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7659 - acc: 0.1741\n",
      "Epoch 936/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7658 - acc: 0.1741\n",
      "Epoch 937/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7658 - acc: 0.1741\n",
      "Epoch 938/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7657 - acc: 0.1741\n",
      "Epoch 939/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7657 - acc: 0.1741\n",
      "Epoch 940/1000\n",
      "201/201 [==============================] - 0s 727us/sample - loss: 1.7657 - acc: 0.1741\n",
      "Epoch 941/1000\n",
      "201/201 [==============================] - 0s 771us/sample - loss: 1.7656 - acc: 0.1741\n",
      "Epoch 942/1000\n",
      "201/201 [==============================] - 0s 966us/sample - loss: 1.7656 - acc: 0.1741\n",
      "Epoch 943/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7655 - acc: 0.1741\n",
      "Epoch 944/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7655 - acc: 0.1741\n",
      "Epoch 945/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7655 - acc: 0.1741\n",
      "Epoch 946/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7654 - acc: 0.1741\n",
      "Epoch 947/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7654 - acc: 0.1741\n",
      "Epoch 948/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7653 - acc: 0.1741\n",
      "Epoch 949/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7653 - acc: 0.1741\n",
      "Epoch 950/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7653 - acc: 0.1741\n",
      "Epoch 951/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7652 - acc: 0.1741\n",
      "Epoch 952/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7652 - acc: 0.1741\n",
      "Epoch 953/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7651 - acc: 0.1741\n",
      "Epoch 954/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7651 - acc: 0.1741\n",
      "Epoch 955/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7651 - acc: 0.1741\n",
      "Epoch 956/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7650 - acc: 0.1741\n",
      "Epoch 957/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7650 - acc: 0.1741\n",
      "Epoch 958/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7649 - acc: 0.1741\n",
      "Epoch 959/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7649 - acc: 0.1741\n",
      "Epoch 960/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7649 - acc: 0.1741\n",
      "Epoch 961/1000\n",
      "201/201 [==============================] - 0s 937us/sample - loss: 1.7648 - acc: 0.1741\n",
      "Epoch 962/1000\n",
      "201/201 [==============================] - 0s 833us/sample - loss: 1.7648 - acc: 0.1741\n",
      "Epoch 963/1000\n",
      "201/201 [==============================] - 0s 884us/sample - loss: 1.7647 - acc: 0.1741\n",
      "Epoch 964/1000\n",
      "201/201 [==============================] - 0s 877us/sample - loss: 1.7647 - acc: 0.1741\n",
      "Epoch 965/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7646 - acc: 0.1741\n",
      "Epoch 966/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7646 - acc: 0.1741\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7646 - acc: 0.1741\n",
      "Epoch 968/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7645 - acc: 0.1741\n",
      "Epoch 969/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7645 - acc: 0.1741\n",
      "Epoch 970/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7644 - acc: 0.1741\n",
      "Epoch 971/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7644 - acc: 0.1741\n",
      "Epoch 972/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7644 - acc: 0.1741\n",
      "Epoch 973/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7643 - acc: 0.1741\n",
      "Epoch 974/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7643 - acc: 0.1741\n",
      "Epoch 975/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7642 - acc: 0.1741\n",
      "Epoch 976/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7642 - acc: 0.1741\n",
      "Epoch 977/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7641 - acc: 0.1741\n",
      "Epoch 978/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7641 - acc: 0.1741\n",
      "Epoch 979/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7641 - acc: 0.1741\n",
      "Epoch 980/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7640 - acc: 0.1741\n",
      "Epoch 981/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7640 - acc: 0.1741\n",
      "Epoch 982/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7639 - acc: 0.1741\n",
      "Epoch 983/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7639 - acc: 0.1741\n",
      "Epoch 984/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7639 - acc: 0.1741\n",
      "Epoch 985/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7638 - acc: 0.1741\n",
      "Epoch 986/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7638 - acc: 0.1741\n",
      "Epoch 987/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7637 - acc: 0.1741\n",
      "Epoch 988/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7637 - acc: 0.1741\n",
      "Epoch 989/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7636 - acc: 0.1741\n",
      "Epoch 990/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7636 - acc: 0.1741\n",
      "Epoch 991/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7636 - acc: 0.1741\n",
      "Epoch 992/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7635 - acc: 0.1741\n",
      "Epoch 993/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7635 - acc: 0.1741\n",
      "Epoch 994/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7634 - acc: 0.1741\n",
      "Epoch 995/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7634 - acc: 0.1741\n",
      "Epoch 996/1000\n",
      "201/201 [==============================] - 0s 1ms/sample - loss: 1.7633 - acc: 0.1741\n",
      "Epoch 997/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7633 - acc: 0.1741\n",
      "Epoch 998/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7633 - acc: 0.1741\n",
      "Epoch 999/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7632 - acc: 0.1741\n",
      "Epoch 1000/1000\n",
      "201/201 [==============================] - 0s 2ms/sample - loss: 1.7632 - acc: 0.1741\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "epochs = 1000\n",
    "model = model.fit(x_train, y_train_binary,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "          #validation_data=(x_test, y_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "specified-stress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 12, 1)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "smaller-double",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 6)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "local-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ends above\n",
    "# Convert class vectors to binary class matrices. This uses 1 hot encoding.\n",
    "#y_train_binary = keras.utils.to_categorical(y_train, num_classes,)\n",
    "#y_test_binary = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-korean",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-procedure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "religious-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition_Crater wear</th>\n",
       "      <th>Condition_Flank Wear</th>\n",
       "      <th>Condition_Good</th>\n",
       "      <th>Condition_Nose Wear</th>\n",
       "      <th>Condition_Notch wear</th>\n",
       "      <th>Condition_Tool breakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Condition_Crater wear  Condition_Flank Wear  Condition_Good  \\\n",
       "0                        0                     0               1   \n",
       "1                        0                     0               1   \n",
       "2                        0                     0               1   \n",
       "3                        0                     0               1   \n",
       "4                        0                     0               1   \n",
       "..                     ...                   ...             ...   \n",
       "295                      1                     0               0   \n",
       "296                      1                     0               0   \n",
       "297                      1                     0               0   \n",
       "298                      1                     0               0   \n",
       "299                      1                     0               0   \n",
       "\n",
       "     Condition_Nose Wear  Condition_Notch wear  Condition_Tool breakage   \n",
       "0                      0                     0                         0  \n",
       "1                      0                     0                         0  \n",
       "2                      0                     0                         0  \n",
       "3                      0                     0                         0  \n",
       "4                      0                     0                         0  \n",
       "..                   ...                   ...                       ...  \n",
       "295                    0                     0                         0  \n",
       "296                    0                     0                         0  \n",
       "297                    0                     0                         0  \n",
       "298                    0                     0                         0  \n",
       "299                    0                     0                         0  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previous code\n",
    "labels = pd.get_dummies(data.Condition, prefix='Condition')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "irish-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a different dataset for the \"Condition\" column\n",
    "y = data.Condition\n",
    "#Dropping the \"Condition\" Column from the original dataset\n",
    "X = data.drop('Condition', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "postal-selling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = labels.values\n",
    "X_columns = data.columns.drop('Condition')\n",
    "X = data[X_columns].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "continued-appraisal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-going",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "black-business",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 6)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting into testing and training data with teh 80:20 ratio\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state= 30)\n",
    "#print(\"\\nX_train:\\n\")\n",
    "#print(X_train.head())\n",
    "#print(X_train.shape)\n",
    "#print(y_train)\n",
    "\n",
    "\n",
    "\n",
    "#print(\"\\nX_test:\\n\")\n",
    "#print(X_test.head())\n",
    "#print(X_test.shape)\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "nasty-alarm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 12, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping xtrain to be 3-d\n",
    "X_train = np.expand_dims(np.random.normal(size=(240, 12)),axis=-1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "effective-arena",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 6, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.expand_dims(np.random.normal(size=(240, 6)),axis=-1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "musical-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np.random.choice([0,1], size=(240,6))\n",
    "#y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "suspected-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/59106391/using-conv1d-error-when-checking-input-expected-conv1d-input-to-have-3-dimensi\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=1, \n",
    "activation='relu',input_shape=(12,1)))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=1, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(240, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "european-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='kullback_leibler_divergence', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='kullback_leibler_divergence', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ambient-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 0s 523us/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 0s 479us/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 0s 481us/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 0s 551us/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 0s 582us/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 0s 583us/sample - loss: 376.6299 - acc: 6.9444e-04\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 0s 573us/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 0s 900us/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 0s 1ms/sample - loss: 376.6299 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 0s 1ms/sample - loss: 376.6299 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,batch_size=8, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tested-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self\n",
    "#CNN\n",
    "#layers.Conv1D(filters=32, kernel_size=3 , activation='relu', input_shape=(12,1)),\n",
    "#layers.MaxPooling1D((2)),\n",
    "    \n",
    "\n",
    "#ANN\n",
    "#https://stackabuse.com/tensorflow-2-0-solving-classification-and-regression-problems/\n",
    "#Creating/defining the Neural Network Model \n",
    "#input_layer = Input(shape=(X.shape[1],))\n",
    "#dense_layer_1 = Dense(12, activation='selu')(input_layer)\n",
    "#dense_layer_2 = Dense(11, activation='selu')(dense_layer_1)\n",
    "#dense_layer_3 = Dense(10, activation='selu')(dense_layer_2)\n",
    "#dense_layer_4 = Dense(9, activation='selu')(dense_layer_3)\n",
    "#dense_layer_5 = Dense(8, activation='selu')(dense_layer_4)\n",
    "#output = Dense(y.shape[1], activation='softmax')(dense_layer_5)\n",
    "\n",
    "#Compiling the model based on above mentioned attributes\n",
    "#model = Model(inputs=input_layer, outputs=output)\n",
    "#model.compile(loss='kullback_leibler_divergence', optimizer='adam', metrics=['acc'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "reverse-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn = models.Sequential([\n",
    " #   layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(12,1)),\n",
    "  #  layers.MaxPooling2D((2, 2)),\n",
    "   # \n",
    "    #layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    #layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #layers.Flatten(),\n",
    "    #layers.Dense(64, activation='relu'),\n",
    "    #layers.Dense(10, activation='softmax')\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ready-speed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,12], [1,3,12,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1811\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1812\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1813\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,12], [1,3,12,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6d333a878b34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconv_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#conv_model.add(layers.Flatten())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    204\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m               \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m     name=None):\n\u001b[1;32m-> 1011\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1012\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1142\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 574\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 574\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[1;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[0;32m   1879\u001b[0m     \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1881\u001b[1;33m       result = gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   1882\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    972\u001b[0m         \"'conv2d' Op, not %r.\" % dilations)\n\u001b[0;32m    973\u001b[0m   \u001b[0mdilations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dilations\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdilations\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m    975\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3475\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3476\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3477\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3478\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3479\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1972\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1974\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   1975\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1813\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1814\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv1d/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](conv1d/conv1d/ExpandDims, conv1d/conv1d/ExpandDims_1)' with input shapes: [?,1,1,12], [1,3,12,32]."
     ]
    }
   ],
   "source": [
    "#conv_model = models.Sequential()\n",
    "#conv_model.add(layers.Conv1D(32, (3), activation='relu' , input_shape=(1,12)))\n",
    "#conv_model.add(layers.Flatten())\n",
    "#conv_model.add(layers.Conv1D(16, (3), activation='relu'))\n",
    "#conv_model.add(layers.Flatten())\n",
    "#conv_model.add(layers.Dense(64, activation='relu'))\n",
    "#conv_model.add(layers.Dense(1, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "devoted-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.compile(loss='binary_crossentropy', optimizer= \"adam\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "chicken-hayes",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_39_input to have 3 dimensions, but got array with shape (240, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-4853c76c87bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m conv_model.fit(X_train, y_train, validation_split = 1/12\n\u001b[0m\u001b[0;32m      2\u001b[0m               ,epochs = 10, batch_size = 1)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m                                                      steps_per_epoch, x)\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m     x, y, sample_weights = model._standardize_user_data(\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2326\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2328\u001b[1;33m     return self._standardize_tensors(\n\u001b[0m\u001b[0;32m   2329\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2330\u001b[0m         \u001b[0mrun_eagerly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2355\u001b[0m       \u001b[1;31m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2356\u001b[1;33m       x = training_utils.standardize_input_data(\n\u001b[0m\u001b[0;32m   2357\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2358\u001b[0m           \u001b[0mfeed_input_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m           raise ValueError('Error when checking ' + exception_prefix +\n\u001b[0m\u001b[0;32m    572\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv1d_39_input to have 3 dimensions, but got array with shape (240, 12)"
     ]
    }
   ],
   "source": [
    "conv_model.fit(X_train, y_train, validation_split = 1/12\n",
    "              ,epochs = 10, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "distinct-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node kl_divergence/Cast (defined at <ipython-input-35-4d73a92af87d>:1) ]] [Op:__inference_train_function_5119]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4d73a92af87d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node kl_divergence/Cast (defined at <ipython-input-35-4d73a92af87d>:1) ]] [Op:__inference_train_function_5119]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, verbose=1,shuffle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
